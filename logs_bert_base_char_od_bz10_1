Loading hyperparameters from config_recovery_OD_bert.json
CUDA_VISIBLE_DEVICES 0
Runing the model from Song
Log file path: ./log_base_OD_bert/ZP.recovery_bertchar.log
device: cuda, n_gpu: 1, grad_accum_steps: 2
loading tokenizer from pretraining
Number of predefined pronouns: 12, they are: dict_values([None, '它', '我', '他', '你', '它们', '她', '我们', '你们', '他们', '她们', 'other'])
Loading data and making batches
Data type: recovery, char2word: first
zp_datastream_char.py: for model_type 'bert_char', 'char2word' not in use
Sentence No. 5957 length 557.
Sentence No. 5963 length 741.
Sentence No. 5965 length 763.
Sentence No. 6216 length 723.
Sentence No. 7187 length 607.
Sentence No. 7596 length 558.
Sentence No. 8623 length 837.
OOV rate: 0.007052106081021781, 1366.0/193701.0
Data type: recovery, char2word: first
zp_datastream_char.py: for model_type 'bert_char', 'char2word' not in use
OOV rate: 0.005591708845504941, 116.0/20745.0
data/BK/test_new.json
Data type: recovery, char2word: first
zp_datastream_char.py: for model_type 'bert_char', 'char2word' not in use
OOV rate: 0.007044193459525403, 179.0/25411.0
data/BK/WF_in.json
Data type: recovery, char2word: first
zp_datastream_char.py: for model_type 'bert_char', 'char2word' not in use
OOV rate: 0.03050871425036236, 1726.0/56574.0
Num training examples = 10497
Num training batches = 2100
Data option: is_shuffle True, is_sort True, is_batch_mix True
Compiling model
Starting the training loop, total steps = 31500
Current epoch takes 2100 steps
step: 0 total loss: 3.1307859420776367 detection : 0.45906639099121094 recovery : 3.0848793983459473
step: 500 total loss: 0.46718037128448486 detection : 0.2913306653499603 recovery : 0.43804728984832764
step: 1000 total loss: 0.17193195223808289 detection : 0.13098067045211792 recovery : 0.15883389115333557
step: 1500 total loss: 0.4611358046531677 detection : 0.24522528052330017 recovery : 0.4366132616996765
step: 2000 total loss: 0.3492211103439331 detection : 0.15807726979255676 recovery : 0.33341339230537415

Training loss: {'total_loss': 1076.4429504014552, 'detection_loss': 418.06320495158434, 'recovery_loss': 658.379745779559}, time: 97.783 sec
Evaluating on dataset with data_type: recovery
Loss: 62.69, time: 3.017 sec
Detection F1: 46.29, Precision: 62.60, Recall: 36.72
Recovery F1: 41.32, Precision: 51.19, Recall: 34.64
Saving weights, F1 0.0 (prev_best) < 0.4132231404958677 (cur)
-------------
test_set_0
Evaluating on dataset with data_type: recovery
Loss: 53.07, time: 3.219 sec
Detection F1: 45.53, Precision: 62.23, Recall: 35.89
Recovery F1: 41.53, Precision: 48.36, Recall: 36.39
test_set_1
Evaluating on dataset with data_type: recovery
Loss: 26.22, time: 3.577 sec
Detection F1: 8.54, Precision: 25.45, Recall: 5.13
Recovery F1: 7.08, Precision: 13.83, Recall: 4.76
=============
Current epoch takes 2100 steps
step: 2500 total loss: 0.5310218930244446 detection : 0.2910368740558624 recovery : 0.5019181966781616
step: 3000 total loss: 0.13014642894268036 detection : 0.1192161813378334 recovery : 0.11822480708360672
step: 3500 total loss: 0.4450591504573822 detection : 0.267652690410614 recovery : 0.41829389333724976
step: 4000 total loss: 0.13202813267707825 detection : 0.10112227499485016 recovery : 0.12191589921712875

Training loss: {'total_loss': 804.3249285276979, 'detection_loss': 303.06933034583926, 'recovery_loss': 501.2555991867557}, time: 99.424 sec
Evaluating on dataset with data_type: recovery
Loss: 55.51, time: 3.062 sec
Detection F1: 53.89, Precision: 64.22, Recall: 46.42
Recovery F1: 42.22, Precision: 49.23, Recall: 36.95
Saving weights, F1 0.4132231404958677 (prev_best) < 0.42216358839050133 (cur)
-------------
test_set_0
Evaluating on dataset with data_type: recovery
Loss: 45.01, time: 3.234 sec
Detection F1: 56.95, Precision: 61.92, Recall: 52.72
Recovery F1: 45.42, Precision: 47.44, Recall: 43.56
test_set_1
Evaluating on dataset with data_type: recovery
Loss: 24.06, time: 3.576 sec
Detection F1: 30.88, Precision: 31.00, Recall: 30.77
Recovery F1: 9.15, Precision: 12.20, Recall: 7.33
=============
Current epoch takes 2100 steps
step: 4500 total loss: 0.17510542273521423 detection : 0.10175477713346481 recovery : 0.16492994129657745
step: 5000 total loss: 0.29125654697418213 detection : 0.0693289190530777 recovery : 0.28432366251945496
step: 5500 total loss: 0.08112083375453949 detection : 0.05168987810611725 recovery : 0.07595184445381165
step: 6000 total loss: 0.030894476920366287 detection : 0.038960061967372894 recovery : 0.026998471468687057

Training loss: {'total_loss': 694.6593858953565, 'detection_loss': 262.1361134527251, 'recovery_loss': 432.52327314182185}, time: 98.704 sec
Evaluating on dataset with data_type: recovery
Loss: 55.70, time: 3.039 sec
Detection F1: 56.79, Precision: 61.62, Recall: 52.66
Recovery F1: 45.37, Precision: 54.17, Recall: 39.03
Saving weights, F1 0.42216358839050133 (prev_best) < 0.4536912751677852 (cur)
-------------
test_set_0
Evaluating on dataset with data_type: recovery
Loss: 46.45, time: 3.167 sec
Detection F1: 60.00, Precision: 60.61, Recall: 59.41
Recovery F1: 46.43, Precision: 48.77, Recall: 44.31
test_set_1
Evaluating on dataset with data_type: recovery
Loss: 22.63, time: 3.553 sec
Detection F1: 30.55, Precision: 29.66, Recall: 31.50
Recovery F1: 6.85, Precision: 10.29, Recall: 5.13
=============
Current epoch takes 2100 steps
step: 6500 total loss: 0.14907164871692657 detection : 0.09055091440677643 recovery : 0.1400165557861328
step: 7000 total loss: 0.13640713691711426 detection : 0.0712011307477951 recovery : 0.1292870193719864
step: 7500 total loss: 0.22381505370140076 detection : 0.15118297934532166 recovery : 0.20869675278663635
step: 8000 total loss: 0.0986461266875267 detection : 0.11280960589647293 recovery : 0.08736516535282135

Training loss: {'total_loss': 598.1312877228484, 'detection_loss': 228.87056071311235, 'recovery_loss': 369.2607268196298}, time: 99.450 sec
Evaluating on dataset with data_type: recovery
Loss: 57.99, time: 3.181 sec
Detection F1: 55.88, Precision: 56.34, Recall: 55.43
Recovery F1: 46.17, Precision: 50.55, Recall: 42.49
Saving weights, F1 0.4536912751677852 (prev_best) < 0.4617314930991217 (cur)
-------------
test_set_0
Evaluating on dataset with data_type: recovery
Loss: 48.76, time: 3.219 sec
Detection F1: 61.43, Precision: 57.58, Recall: 65.84
Recovery F1: 45.95, Precision: 45.61, Recall: 46.29
test_set_1
Evaluating on dataset with data_type: recovery
Loss: 24.58, time: 3.584 sec
Detection F1: 36.48, Precision: 28.20, Recall: 51.65
Recovery F1: 8.91, Precision: 9.47, Recall: 8.42
=============
Current epoch takes 2100 steps
step: 8500 total loss: 0.0684022530913353 detection : 0.1079661101102829 recovery : 0.05760563910007477
step: 9000 total loss: 0.28911280632019043 detection : 0.15496483445167542 recovery : 0.27361631393432617
step: 9500 total loss: 0.09694945067167282 detection : 0.027275431901216507 recovery : 0.09422190487384796
step: 10000 total loss: 0.12446016818284988 detection : 0.08478472381830215 recovery : 0.11598169803619385

Training loss: {'total_loss': 508.8529806016013, 'detection_loss': 197.51494569331408, 'recovery_loss': 311.3380347720231}, time: 99.096 sec
Evaluating on dataset with data_type: recovery
Loss: 62.59, time: 3.047 sec
Detection F1: 55.82, Precision: 57.46, Recall: 54.27
Recovery F1: 47.23, Precision: 50.53, Recall: 44.34
Saving weights, F1 0.4617314930991217 (prev_best) < 0.4723247232472325 (cur)
-------------
test_set_0
Evaluating on dataset with data_type: recovery
Loss: 51.26, time: 3.236 sec
Detection F1: 60.60, Precision: 58.70, Recall: 62.62
Recovery F1: 45.07, Precision: 44.36, Recall: 45.79
test_set_1
Evaluating on dataset with data_type: recovery
Loss: 24.83, time: 3.583 sec
Detection F1: 35.90, Precision: 29.09, Recall: 46.89
Recovery F1: 9.85, Precision: 9.82, Recall: 9.89
=============
Current epoch takes 2100 steps
step: 10500 total loss: 0.17931051552295685 detection : 0.08681689947843552 recovery : 0.17062883079051971
step: 11000 total loss: 0.688445508480072 detection : 0.0858493372797966 recovery : 0.6798605918884277
step: 11500 total loss: 0.10439660400152206 detection : 0.05864240229129791 recovery : 0.09853236377239227
step: 12000 total loss: 0.3646222651004791 detection : 0.23001544177532196 recovery : 0.34162071347236633
step: 12500 total loss: 0.06656653434038162 detection : 0.04656177759170532 recovery : 0.06191035360097885

Training loss: {'total_loss': 423.67490393924527, 'detection_loss': 167.0282064722851, 'recovery_loss': 256.646697455144}, time: 98.446 sec
Evaluating on dataset with data_type: recovery
Loss: 67.99, time: 3.049 sec
Detection F1: 57.14, Precision: 52.41, Recall: 62.82
Recovery F1: 46.02, Precision: 43.06, Recall: 49.42
-------------
test_set_0
Evaluating on dataset with data_type: recovery
Loss: 59.09, time: 3.161 sec
Detection F1: 59.63, Precision: 50.87, Recall: 72.03
Recovery F1: 44.42, Precision: 38.12, Recall: 53.22
test_set_1
Evaluating on dataset with data_type: recovery
Loss: 28.46, time: 3.568 sec
Detection F1: 34.86, Precision: 25.08, Recall: 57.14
Recovery F1: 9.27, Precision: 7.83, Recall: 11.36
=============
Current epoch takes 2100 steps
step: 13000 total loss: 0.09087299555540085 detection : 0.08674290776252747 recovery : 0.08219870179891586
step: 13500 total loss: 0.022297054529190063 detection : 0.018895547837018967 recovery : 0.020407499745488167
step: 14000 total loss: 0.06969865411520004 detection : 0.04537545517086983 recovery : 0.06516110897064209
step: 14500 total loss: 0.1450543999671936 detection : 0.10187418758869171 recovery : 0.13486698269844055

Training loss: {'total_loss': 379.546906481497, 'detection_loss': 153.53883790085092, 'recovery_loss': 226.00806843413739}, time: 98.649 sec
Evaluating on dataset with data_type: recovery
Loss: 64.45, time: 3.109 sec
Detection F1: 56.59, Precision: 52.80, Recall: 60.97
Recovery F1: 44.37, Precision: 44.63, Recall: 44.11
-------------
test_set_0
Evaluating on dataset with data_type: recovery
Loss: 57.10, time: 3.175 sec
Detection F1: 60.90, Precision: 53.57, Recall: 70.54
Recovery F1: 44.82, Precision: 41.12, Recall: 49.26
test_set_1
Evaluating on dataset with data_type: recovery
Loss: 27.76, time: 3.579 sec
Detection F1: 36.30, Precision: 27.01, Recall: 55.31
Recovery F1: 11.28, Precision: 10.30, Recall: 12.45
=============
Current epoch takes 2100 steps
step: 15000 total loss: 0.05356802046298981 detection : 0.044881563633680344 recovery : 0.04907986521720886
step: 15500 total loss: 0.08705685287714005 detection : 0.0736975222826004 recovery : 0.07968710362911224
step: 16000 total loss: 0.07504229992628098 detection : 0.08225788176059723 recovery : 0.06681650876998901
step: 16500 total loss: 0.36044803261756897 detection : 0.24393463134765625 recovery : 0.33605456352233887

Training loss: {'total_loss': 340.08648927300237, 'detection_loss': 142.23910233390052, 'recovery_loss': 197.8473866264685}, time: 98.671 sec
Evaluating on dataset with data_type: recovery
Loss: 73.10, time: 3.157 sec
Detection F1: 54.23, Precision: 51.12, Recall: 57.74
Recovery F1: 47.29, Precision: 47.24, Recall: 47.34
Saving weights, F1 0.4723247232472325 (prev_best) < 0.4728950403690888 (cur)
-------------
test_set_0
Evaluating on dataset with data_type: recovery
Loss: 63.81, time: 3.223 sec
Detection F1: 58.42, Precision: 51.31, Recall: 67.82
Recovery F1: 44.62, Precision: 40.44, Recall: 49.75
test_set_1
Evaluating on dataset with data_type: recovery
Loss: 28.98, time: 3.586 sec
Detection F1: 37.21, Precision: 27.68, Recall: 56.78
Recovery F1: 10.35, Precision: 8.85, Recall: 12.45
=============
Current epoch takes 2100 steps
step: 17000 total loss: 0.025728678330779076 detection : 0.04544807970523834 recovery : 0.02118387073278427
step: 17500 total loss: 0.01675865426659584 detection : 0.04696479067206383 recovery : 0.012062174268066883
step: 18000 total loss: 0.124311164021492 detection : 0.1023835688829422 recovery : 0.11407280713319778
step: 18500 total loss: 0.08764535933732986 detection : 0.04926254227757454 recovery : 0.0827191025018692

Training loss: {'total_loss': 291.02240634988993, 'detection_loss': 123.96649669937324, 'recovery_loss': 167.05590949830366}, time: 99.837 sec
Evaluating on dataset with data_type: recovery
Loss: 76.68, time: 3.036 sec
Detection F1: 57.20, Precision: 52.84, Recall: 62.36
Recovery F1: 46.00, Precision: 44.93, Recall: 47.11
-------------
test_set_0
Evaluating on dataset with data_type: recovery
Loss: 69.73, time: 3.141 sec
Detection F1: 59.35, Precision: 50.34, Recall: 72.28
Recovery F1: 44.68, Precision: 39.47, Recall: 51.49
test_set_1
Evaluating on dataset with data_type: recovery
Loss: 32.79, time: 3.560 sec
Detection F1: 35.25, Precision: 25.49, Recall: 57.14
Recovery F1: 10.98, Precision: 9.07, Recall: 13.92
=============
Current epoch takes 2100 steps
step: 19000 total loss: 0.008856397122144699 detection : 0.006172998808324337 recovery : 0.008239096961915493
step: 19500 total loss: 0.09348727017641068 detection : 0.08714155852794647 recovery : 0.08477311581373215
step: 20000 total loss: 0.06723491102457047 detection : 0.009415101259946823 recovery : 0.06629340350627899
step: 20500 total loss: 0.05261732265353203 detection : 0.0299556702375412 recovery : 0.04962175711989403

Training loss: {'total_loss': 252.03773726336658, 'detection_loss': 110.40855299105169, 'recovery_loss': 141.6291841896018}, time: 99.141 sec
Evaluating on dataset with data_type: recovery
Loss: 77.19, time: 3.184 sec
Detection F1: 57.64, Precision: 51.85, Recall: 64.90
Recovery F1: 45.68, Precision: 42.46, Recall: 49.42
-------------
test_set_0
Evaluating on dataset with data_type: recovery
Loss: 72.29, time: 3.197 sec
Detection F1: 58.51, Precision: 48.38, Recall: 74.01
Recovery F1: 42.15, Precision: 35.68, Recall: 51.49
test_set_1
Evaluating on dataset with data_type: recovery
Loss: 31.09, time: 3.569 sec
Detection F1: 34.82, Precision: 25.65, Recall: 54.21
Recovery F1: 11.51, Precision: 10.00, Recall: 13.55
=============
Current epoch takes 2100 steps
step: 21000 total loss: 0.018114794045686722 detection : 0.017725789919495583 recovery : 0.01634221524000168
step: 21500 total loss: 0.003443886525928974 detection : 0.003496810095384717 recovery : 0.0030942056328058243
step: 22000 total loss: 0.018925976008176804 detection : 0.02361989952623844 recovery : 0.016563985496759415
step: 22500 total loss: 0.03051527962088585 detection : 0.025143707171082497 recovery : 0.028000907972455025
step: 23000 total loss: 0.269864946603775 detection : 0.2194165587425232 recovery : 0.24792328476905823

Training loss: {'total_loss': 224.91565755591728, 'detection_loss': 98.94925637461711, 'recovery_loss': 125.96640107710846}, time: 99.608 sec
Evaluating on dataset with data_type: recovery
Loss: 83.06, time: 3.036 sec
Detection F1: 57.23, Precision: 50.90, Recall: 65.36
Recovery F1: 47.37, Precision: 42.75, Recall: 53.12
Saving weights, F1 0.4728950403690888 (prev_best) < 0.47373841400617916 (cur)
-------------
test_set_0
Evaluating on dataset with data_type: recovery
Loss: 76.03, time: 3.238 sec
Detection F1: 58.85, Precision: 48.63, Recall: 74.50
Recovery F1: 42.40, Precision: 35.57, Recall: 52.48
test_set_1
Evaluating on dataset with data_type: recovery
Loss: 36.40, time: 3.581 sec
Detection F1: 33.09, Precision: 23.05, Recall: 58.61
Recovery F1: 12.65, Precision: 9.76, Recall: 17.95
=============
Current epoch takes 2100 steps
step: 23500 total loss: 0.055254336446523666 detection : 0.028492672368884087 recovery : 0.05240507051348686
step: 24000 total loss: 0.05648459494113922 detection : 0.11858951300382614 recovery : 0.04462564364075661
step: 24500 total loss: 0.0986056700348854 detection : 0.05680368095636368 recovery : 0.0929253026843071
step: 25000 total loss: 0.1560802012681961 detection : 0.10412436723709106 recovery : 0.14566776156425476

Training loss: {'total_loss': 198.3326727753738, 'detection_loss': 88.708674681111, 'recovery_loss': 109.62399800767889}, time: 99.165 sec
Evaluating on dataset with data_type: recovery
Loss: 83.44, time: 3.155 sec
Detection F1: 56.04, Precision: 53.46, Recall: 58.89
Recovery F1: 45.45, Precision: 44.74, Recall: 46.19
-------------
test_set_0
Evaluating on dataset with data_type: recovery
Loss: 76.98, time: 3.174 sec
Detection F1: 59.80, Precision: 54.11, Recall: 66.83
Recovery F1: 46.29, Precision: 42.39, Recall: 50.99
test_set_1
Evaluating on dataset with data_type: recovery
Loss: 34.71, time: 3.578 sec
Detection F1: 35.11, Precision: 26.22, Recall: 53.11
Recovery F1: 11.09, Precision: 9.22, Recall: 13.92
=============
Current epoch takes 2100 steps
step: 25500 total loss: 0.07038266956806183 detection : 0.049109090119600296 recovery : 0.06547176092863083
step: 26000 total loss: 0.017734240740537643 detection : 0.02131655439734459 recovery : 0.01560258585959673
step: 26500 total loss: 0.0777176171541214 detection : 0.07030104845762253 recovery : 0.07068751007318497
step: 27000 total loss: 0.030147623270750046 detection : 0.032583869993686676 recovery : 0.026889236643910408

Training loss: {'total_loss': 178.2351696230471, 'detection_loss': 82.59726442955434, 'recovery_loss': 95.63790509168757}, time: 98.808 sec
Evaluating on dataset with data_type: recovery
Loss: 91.33, time: 3.050 sec
Detection F1: 56.60, Precision: 54.49, Recall: 58.89
Recovery F1: 44.21, Precision: 44.79, Recall: 43.65
-------------
test_set_0
Evaluating on dataset with data_type: recovery
Loss: 85.13, time: 3.175 sec
Detection F1: 58.22, Precision: 52.82, Recall: 64.85
Recovery F1: 45.38, Precision: 42.07, Recall: 49.26
test_set_1
Evaluating on dataset with data_type: recovery
Loss: 33.84, time: 3.575 sec
Detection F1: 36.82, Precision: 28.08, Recall: 53.48
Recovery F1: 11.59, Precision: 9.92, Recall: 13.92
=============
Current epoch takes 2100 steps
step: 27500 total loss: 0.004930461291223764 detection : 0.0018626062665134668 recovery : 0.004744200501590967
step: 28000 total loss: 0.03435920178890228 detection : 0.02751491777598858 recovery : 0.03160770982503891
step: 28500 total loss: 0.0018759206868708134 detection : 0.007619420066475868 recovery : 0.0011139786802232265
step: 29000 total loss: 0.011705542914569378 detection : 0.0012689947616308928 recovery : 0.011578643694519997

Training loss: {'total_loss': 160.3569904937758, 'detection_loss': 74.99486518146296, 'recovery_loss': 85.3621253559977}, time: 99.566 sec
Evaluating on dataset with data_type: recovery
Loss: 91.60, time: 3.042 sec
Detection F1: 53.64, Precision: 55.42, Recall: 51.96
Recovery F1: 45.39, Precision: 49.32, Recall: 42.03
-------------
test_set_0
Evaluating on dataset with data_type: recovery
Loss: 85.29, time: 3.176 sec
Detection F1: 58.88, Precision: 56.78, Recall: 61.14
Recovery F1: 46.21, Precision: 44.96, Recall: 47.52
test_set_1
Evaluating on dataset with data_type: recovery
Loss: 33.52, time: 3.574 sec
Detection F1: 36.95, Precision: 30.05, Recall: 47.99
Recovery F1: 12.34, Precision: 11.08, Recall: 13.92
=============
Current epoch takes 2100 steps
step: 29500 total loss: 0.029256822541356087 detection : 0.03636079654097557 recovery : 0.02562074363231659
step: 30000 total loss: 0.043471790850162506 detection : 0.022166378796100616 recovery : 0.041255153715610504
step: 30500 total loss: 0.003815382719039917 detection : 0.0011269670212641358 recovery : 0.003702685935422778
step: 31000 total loss: 0.00013257590762805194 detection : 0.0005758073530159891 recovery : 7.499517232645303e-05

Training loss: {'total_loss': 118.01272107291152, 'detection_loss': 54.92892175898305, 'recovery_loss': 63.083799435677065}, time: 100.305 sec
Evaluating on dataset with data_type: recovery
Loss: 99.43, time: 2.988 sec
Detection F1: 58.01, Precision: 54.58, Recall: 61.89
Recovery F1: 46.40, Precision: 45.27, Recall: 47.58
-------------
test_set_0
Evaluating on dataset with data_type: recovery
Loss: 93.22, time: 3.124 sec
Detection F1: 60.19, Precision: 52.91, Recall: 69.80
Recovery F1: 46.34, Precision: 41.49, Recall: 52.48
test_set_1
Evaluating on dataset with data_type: recovery
Loss: 37.60, time: 3.582 sec
Detection F1: 36.16, Precision: 27.41, Recall: 53.11
Recovery F1: 11.94, Precision: 10.26, Recall: 14.29
=============
